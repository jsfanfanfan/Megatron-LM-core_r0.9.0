examples/multimodal/pretrain-freeze-llm-hete-2080first.sh: line 4: activate: No such file or directory
2
[2024-12-25 14:43:50,721] torch.distributed.run: [WARNING] 
[2024-12-25 14:43:50,721] torch.distributed.run: [WARNING] *****************************************
[2024-12-25 14:43:50,721] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-12-25 14:43:50,721] torch.distributed.run: [WARNING] *****************************************
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
------pipeline_parallel_model_size:4------
------world_size:16------
------total_model_size:4------
------num_pipeline_model_parallel_groups:4------
------pipeline_parallel_model_size:4------
------world_size:16------
------total_model_size:4------
------num_pipeline_model_parallel_groups:4------
------pipeline_parallel_model_size:4------
------world_size:16------
------total_model_size:4------
------num_pipeline_model_parallel_groups:4------
------pipeline_parallel_model_size:4------
------world_size:16------
------total_model_size:4------
------num_pipeline_model_parallel_groups:4------
---Rank 9---Tensor Parallel Group GPUs: [0]---Rank 8---Tensor Parallel Group GPUs: [0]
---Rank 10---Tensor Parallel Group GPUs: [0]

---Rank 9---Pipeline Parallel Group GPUs: [2, 2, 2, 2]
---Rank 8---Pipeline Parallel Group GPUs: [2, 2, 2, 2]
---Rank 10---Pipeline Parallel Group GPUs: [2, 2, 2, 2]
---Rank 11---Tensor Parallel Group GPUs: [0]
[rank9]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank8]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
---Rank 11---Pipeline Parallel Group GPUs: [2, 2, 2, 2]
[rank10]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank11]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
WARNING:megatron.core.models.multimodal.llava_model:LLaVA model is under active development. It may be missing features and its methods may change.
WARNING:megatron.core.models.multimodal.llava_model:LLaVA model is under active development. It may be missing features and its methods may change.
WARNING:megatron.core.models.multimodal.llava_model:LLaVA model is under active development. It may be missing features and its methods may change.
WARNING:megatron.core.models.multimodal.llava_model:LLaVA model is under active development. It may be missing features and its methods may change.
 > number of parameters on (tensor, pipeline) model parallel rank (0, 2): 1308672000
rank=1, worker=0: shard_range=[pretrain-2.tar[5000, 5100), pretrain-2.tar[5100, 5200), pretrain-2.tar[5200, 5300), ...<619>, pretrain-25.tar[7200, 7300), pretrain-25.tar[7300, 7400), pretrain-25.tar[7400, 7500)] sum(count)=62500
rank=1, worker=1: shard_range=[pretrain-25.tar[7500, 7600), pretrain-25.tar[7600, 7700), pretrain-25.tar[7700, 7800), ...<619>, pretrain-30.tar[9700, 9800), pretrain-30.tar[9800, 9900), pretrain-30.tar[9900, 10000)] sum(count)=62500
rank=0, worker=0: shard_range=[pretrain-0.tar[0, 100), pretrain-0.tar[100, 200), pretrain-0.tar[200, 300), ...<619>, pretrain-14.tar[2200, 2300), pretrain-14.tar[2300, 2400), pretrain-14.tar[2400, 2500)] sum(count)=62500
rank=0, worker=1: shard_range=[pretrain-14.tar[2500, 2600), pretrain-14.tar[2600, 2700), pretrain-14.tar[2700, 2800), ...<619>, pretrain-2.tar[4700, 4800), pretrain-2.tar[4800, 4900), pretrain-2.tar[4900, 5000)] sum(count)=62500
rank=2, worker=0: shard_range=[pretrain-31.tar[0, 100), pretrain-31.tar[100, 200), pretrain-31.tar[200, 300), ...<619>, pretrain-37.tar[2200, 2300), pretrain-37.tar[2300, 2400), pretrain-37.tar[2400, 2500)] sum(count)=62500
rank=2, worker=1: shard_range=[pretrain-37.tar[2500, 2600), pretrain-37.tar[2600, 2700), pretrain-37.tar[2700, 2800), ...<619>, pretrain-42.tar[4700, 4800), pretrain-42.tar[4800, 4900), pretrain-42.tar[4900, 5000)] sum(count)=62500
rank=3, worker=0: shard_range=[pretrain-42.tar[5000, 5100), pretrain-42.tar[5100, 5200), pretrain-42.tar[5200, 5300), ...<619>, pretrain-48.tar[7200, 7300), pretrain-48.tar[7300, 7400), pretrain-48.tar[7400, 7500)] sum(count)=62500
rank=3, worker=1: shard_range=[pretrain-48.tar[7500, 7600), pretrain-48.tar[7600, 7700), pretrain-48.tar[7700, 7800), ...<619>, pretrain-53.tar[9700, 9800), pretrain-53.tar[9800, 9900), pretrain-53.tar[9900, 10000)] sum(count)=62500
rank=1, worker=0: shard_range=[pretrain-55.tar[4532, 8128), pretrain-6.tar[0, 3670)] sum(count)=7266
rank=1, worker=1: shard_range=[pretrain-6.tar[3670, 10000), pretrain-7.tar[0, 936)] sum(count)=7266
rank=3, worker=0: shard_range=[pretrain-8.tar[5468, 10000), pretrain-9.tar[0, 2734)] sum(count)=7266
rank=3, worker=1: shard_range=[pretrain-9.tar[2734, 10000)] sum(count)=7266
rank=0, worker=0: shard_range=[pretrain-54.tar[0, 7266)] sum(count)=7266
rank=0, worker=1: shard_range=[pretrain-54.tar[7266, 10000), pretrain-55.tar[0, 4532)] sum(count)=7266
rank=2, worker=0: shard_range=[pretrain-7.tar[936, 8202)] sum(count)=7266
rank=2, worker=1: shard_range=[pretrain-7.tar[8202, 10000), pretrain-8.tar[0, 5468)] sum(count)=7266
Traceback (most recent call last):
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/examples/multimodal/train.py", line 456, in <module>
Traceback (most recent call last):
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/examples/multimodal/train.py", line 456, in <module>
Traceback (most recent call last):
Traceback (most recent call last):
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/examples/multimodal/train.py", line 456, in <module>
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/examples/multimodal/train.py", line 456, in <module>
    pretrain(
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/training/training.py", line 407, in pretrain
    pretrain(
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/training/training.py", line 407, in pretrain
    pretrain(
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/training/training.py", line 407, in pretrain
    pretrain(
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/training/training.py", line 407, in pretrain
    iteration, num_floating_point_operations_so_far = train( # 调用 1172 行进行训练
      File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/training/training.py", line 1375, in train
    iteration, num_floating_point_operations_so_far = train( # 调用 1172 行进行训练    iteration, num_floating_point_operations_so_far = train( # 调用 1172 行进行训练
iteration, num_floating_point_operations_so_far = train( # 调用 1172 行进行训练

  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/training/training.py", line 1375, in train
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/training/training.py", line 1375, in train
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/training/training.py", line 1375, in train
    train_step(forward_step_func, # 调用 805 行
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/training/training.py", line 854, in train_step
    train_step(forward_step_func, # 调用 805 行
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/training/training.py", line 854, in train_step
    train_step(forward_step_func, # 调用 805 行
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/training/training.py", line 854, in train_step
    train_step(forward_step_func, # 调用 805 行
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/training/training.py", line 854, in train_step
    losses_reduced = forward_backward_func( # schedules.py 1345 行 forward_backward_pipelining_without_interleaving
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/core/pipeline_parallel/schedules.py", line 1472, in forward_backward_pipelining_without_interleaving
    losses_reduced = forward_backward_func( # schedules.py 1345 行 forward_backward_pipelining_without_interleaving
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/core/pipeline_parallel/schedules.py", line 1472, in forward_backward_pipelining_without_interleaving
    losses_reduced = forward_backward_func( # schedules.py 1345 行 forward_backward_pipelining_without_interleaving
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/core/pipeline_parallel/schedules.py", line 1472, in forward_backward_pipelining_without_interleaving
    losses_reduced = forward_backward_func( # schedules.py 1345 行 forward_backward_pipelining_without_interleaving
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/core/pipeline_parallel/schedules.py", line 1472, in forward_backward_pipelining_without_interleaving
    input_tensor = recv_forward(recv_tensor_shapes, config)
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/core/pipeline_parallel/schedules.py", line 1280, in recv_forward
    input_tensor = recv_forward(recv_tensor_shapes, config)    
    input_tensor = recv_forward(recv_tensor_shapes, config)input_tensor = recv_forward(recv_tensor_shapes, config)
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/core/pipeline_parallel/schedules.py", line 1280, in recv_forward

  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/core/pipeline_parallel/schedules.py", line 1280, in recv_forward
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/core/pipeline_parallel/schedules.py", line 1280, in recv_forward
    input_tensors.append(p2p_communication.recv_forward(tensor_shape, config))
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/core/pipeline_parallel/p2p_communication.py", line 421, in recv_forward
    input_tensors.append(p2p_communication.recv_forward(tensor_shape, config))
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/core/pipeline_parallel/p2p_communication.py", line 421, in recv_forward
    input_tensors.append(p2p_communication.recv_forward(tensor_shape, config))
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/core/pipeline_parallel/p2p_communication.py", line 421, in recv_forward
    input_tensors.append(p2p_communication.recv_forward(tensor_shape, config))
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/core/pipeline_parallel/p2p_communication.py", line 421, in recv_forward
    input_tensor, _, _ = _communicate(
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/core/pipeline_parallel/p2p_communication.py", line 370, in _communicate
        input_tensor, _, _ = _communicate(input_tensor, _, _ = _communicate(

  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/core/pipeline_parallel/p2p_communication.py", line 370, in _communicate
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/core/pipeline_parallel/p2p_communication.py", line 370, in _communicate
    input_tensor, _, _ = _communicate(
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/core/pipeline_parallel/p2p_communication.py", line 370, in _communicate
    p2p_func(
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/core/pipeline_parallel/p2p_communication.py", line 153, in _batched_p2p_ops
    p2p_func(
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/core/pipeline_parallel/p2p_communication.py", line 153, in _batched_p2p_ops
    p2p_func(
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/core/pipeline_parallel/p2p_communication.py", line 153, in _batched_p2p_ops
    p2p_func(
  File "/gf3/home/fjs/project/MLLM/Megatron-LM-core_r0.9.0/megatron/core/pipeline_parallel/p2p_communication.py", line 153, in _batched_p2p_ops
        reqs = torch.distributed.batch_isend_irecv(ops)reqs = torch.distributed.batch_isend_irecv(ops)

      File "/gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1865, in batch_isend_irecv
  File "/gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1865, in batch_isend_irecv
reqs = torch.distributed.batch_isend_irecv(ops)
  File "/gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1865, in batch_isend_irecv
    reqs = torch.distributed.batch_isend_irecv(ops)
  File "/gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1865, in batch_isend_irecv
    p2p_op.op(p2p_op.tensor, p2p_op.peer, p2p_op.group, p2p_op.tag)
      File "/gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1631, in irecv
p2p_op.op(p2p_op.tensor, p2p_op.peer, p2p_op.group, p2p_op.tag)
  File "/gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1631, in irecv
    p2p_op.op(p2p_op.tensor, p2p_op.peer, p2p_op.group, p2p_op.tag)
  File "/gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1631, in irecv
    p2p_op.op(p2p_op.tensor, p2p_op.peer, p2p_op.group, p2p_op.tag)
  File "/gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1631, in irecv
    return pg.recv([tensor], group_src_rank, tag)
torch.distributed.DistBackendError: [2] is setting up NCCL communicator and retrieving ncclUniqueId from [0] via c10d key-value store by key '0', but store->get('0') got error: Connection reset by peer
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:670 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f8acb93bd87 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5894fde (0x7f8b07634fde in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0x360 (0x7f8b0762f7f0 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x32 (0x7f8b0762fb32 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0xa1 (0x7f8b07630961 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7f8b075e5dd1 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7f8b075e5dd1 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7f8b075e5dd1 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7f8b075e5dd1 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #9: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7f8b075e5dd1 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #10: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, std::string const&, int) + 0xa9 (0x7f8accab74e9 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, int, bool) + 0x22b (0x7f8accabe4db in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::recv(std::vector<at::Tensor, std::allocator<at::Tensor> >&, int, int) + 0x550 (0x7f8accae13e0 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #13: <unknown function> + 0x5838289 (0x7f8b075d8289 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #14: <unknown function> + 0x5843180 (0x7f8b075e3180 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x5843215 (0x7f8b075e3215 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x4e8937c (0x7f8b06c2937c in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x1a08a38 (0x7f8b037a8a38 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #18: <unknown function> + 0x58498d4 (0x7f8b075e98d4 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0x584eb85 (0x7f8b075eeb85 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #20: <unknown function> + 0xc99c3e (0x7f8b19e99c3e in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #21: <unknown function> + 0x413f64 (0x7f8b19613f64 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #22: <unknown function> + 0x1457e6 (0x5568f46cd7e6 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #23: _PyObject_MakeTpCall + 0x26b (0x5568f46c69db in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #24: <unknown function> + 0x151ec6 (0x5568f46d9ec6 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #25: _PyEval_EvalFrameDefault + 0x4c1a (0x5568f46c1f2a in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #26: _PyFunction_Vectorcall + 0x6c (0x5568f46cdc6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #27: _PyEval_EvalFrameDefault + 0x4c1a (0x5568f46c1f2a in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #28: _PyFunction_Vectorcall + 0x6c (0x5568f46cdc6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #29: _PyEval_EvalFrameDefault + 0x4c1a (0x5568f46c1f2a in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #30: _PyFunction_Vectorcall + 0x6c (0x5568f46cdc6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #31: _PyEval_EvalFrameDefault + 0x13cc (0x5568f46be6dc in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #32: _PyFunction_Vectorcall + 0x6c (0x5568f46cdc6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #33: _PyEval_EvalFrameDefault + 0x13cc (0x5568f46be6dc in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #34: _PyFunction_Vectorcall + 0x6c (0x5568f46cdc6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #35: _PyEval_EvalFrameDefault + 0x4c1a (0x5568f46c1f2a in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #36: _PyFunction_Vectorcall + 0x6c (0x5568f46cdc6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #37: _PyEval_EvalFrameDefault + 0x320 (0x5568f46bd630 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #38: _PyFunction_Vectorcall + 0x6c (0x5568f46cdc6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #39: _PyEval_EvalFrameDefault + 0x13cc (0x5568f46be6dc in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #40: _PyFunction_Vectorcall + 0x6c (0x5568f46cdc6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #41: _PyEval_EvalFrameDefault + 0x320 (0x5568f46bd630 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #42: _PyFunction_Vectorcall + 0x6c (0x5568f46cdc6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #43: _PyEval_EvalFrameDefault + 0x320 (0x5568f46bd630 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #44: _PyFunction_Vectorcall + 0x6c (0x5568f46cdc6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #45: _PyEval_EvalFrameDefault + 0x13cc (0x5568f46be6dc in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #46: <unknown function> + 0x1da820 (0x5568f4762820 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #47: PyEval_EvalCode + 0x87 (0x5568f4762767 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #48: <unknown function> + 0x20ac2a (0x5568f4792c2a in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #49: <unknown function> + 0x206023 (0x5568f478e023 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #50: <unknown function> + 0x9a558 (0x5568f4622558 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #51: _PyRun_SimpleFileObject + 0x1ae (0x5568f478850e in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #52: _PyRun_AnyFileObject + 0x44 (0x5568f47880a4 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #53: Py_RunMain + 0x38b (0x5568f478529b in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #54: Py_BytesMain + 0x37 (0x5568f4756257 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #55: __libc_start_main + 0xe7 (0x7f8b1bd32c87 in /lib/x86_64-linux-gnu/libc.so.6)
frame #56: <unknown function> + 0x1ce151 (0x5568f4756151 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
. This may indicate a possible application crash on rank 0 or a network set up issue.
    return pg.recv([tensor], group_src_rank, tag)
torch.distributed    .return pg.recv([tensor], group_src_rank, tag)DistBackendError
: [2] is setting up NCCL communicator and retrieving ncclUniqueId from [0] via c10d key-value store by key '0', but store->get('0') got error: Connection reset by peer
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:670 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fd2b3f9bd87 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5894fde (0x7fd2efc94fde in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0x360 (0x7fd2efc8f7f0 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x32 (0x7fd2efc8fb32 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0xa1 (0x7fd2efc90961 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fd2efc45dd1 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fd2efc45dd1 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fd2efc45dd1 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fd2efc45dd1 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #9: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fd2efc45dd1 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #10: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, std::string const&, int) + 0xa9 (0x7fd2b51174e9 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, int, bool) + 0x22b (0x7fd2b511e4db in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::recv(std::vector<at::Tensor, std::allocator<at::Tensor> >&, int, int) + 0x550 (0x7fd2b51413e0 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #13: <unknown function> + 0x5838289 (0x7fd2efc38289 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #14: <unknown function> + 0x5843180 (0x7fd2efc43180 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x5843215 (0x7fd2efc43215 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x4e8937c (0x7fd2ef28937c in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x1a08a38 (0x7fd2ebe08a38 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #18: <unknown function> + 0x58498d4 (0x7fd2efc498d4 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0x584eb85 (0x7fd2efc4eb85 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #20: <unknown function> + 0xc99c3e (0x7fd3024f9c3e in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #21: <unknown function> + 0x413f64 (0x7fd301c73f64 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #22: <unknown function> + 0x1457e6 (0x556d4eac57e6 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #23: _PyObject_MakeTpCall + 0x26b (0x556d4eabe9db in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #24: <unknown function> + 0x151ec6 (0x556d4ead1ec6 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #25: _PyEval_EvalFrameDefault + 0x4c1a (0x556d4eab9f2a in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #26: _PyFunction_Vectorcall + 0x6c (0x556d4eac5c6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #27: _PyEval_EvalFrameDefault + 0x4c1a (0x556d4eab9f2a in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #28: _PyFunction_Vectorcall + 0x6c (0x556d4eac5c6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #29: _PyEval_EvalFrameDefault + 0x4c1a (0x556d4eab9f2a in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #30: _PyFunction_Vectorcall + 0x6c (0x556d4eac5c6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #31: _PyEval_EvalFrameDefault + 0x13cc (0x556d4eab66dc in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #32: _PyFunction_Vectorcall + 0x6c (0x556d4eac5c6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #33: _PyEval_EvalFrameDefault + 0x13cc (0x556d4eab66dc in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #34: _PyFunction_Vectorcall + 0x6c (0x556d4eac5c6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #35: _PyEval_EvalFrameDefault + 0x4c1a (0x556d4eab9f2a in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #36: _PyFunction_Vectorcall + 0x6c (0x556d4eac5c6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #37: _PyEval_EvalFrameDefault + 0x320 (0x556d4eab5630 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #38: _PyFunction_Vectorcall + 0x6c (0x556d4eac5c6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #39: _PyEval_EvalFrameDefault + 0x13cc (0x556d4eab66dc in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #40: _PyFunction_Vectorcall + 0x6c (0x556d4eac5c6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #41: _PyEval_EvalFrameDefault + 0x320 (0x556d4eab5630 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #42: _PyFunction_Vectorcall + 0x6c (0x556d4eac5c6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #43: _PyEval_EvalFrameDefault + 0x320 (0x556d4eab5630 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #44: _PyFunction_Vectorcall + 0x6c (0x556d4eac5c6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #45: _PyEval_EvalFrameDefault + 0x13cc (0x556d4eab66dc in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #46: <unknown function> + 0x1da820 (0x556d4eb5a820 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #47: PyEval_EvalCode + 0x87 (0x556d4eb5a767 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #48: <unknown function> + 0x20ac2a (0x556d4eb8ac2a in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #49: <unknown function> + 0x206023 (0x556d4eb86023 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #50: <unknown function> + 0x9a558 (0x556d4ea1a558 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #51: _PyRun_SimpleFileObject + 0x1ae (0x556d4eb8050e in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #52: _PyRun_AnyFileObject + 0x44 (0x556d4eb800a4 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #53: Py_RunMain + 0x38b (0x556d4eb7d29b in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #54: Py_BytesMain + 0x37 (0x556d4eb4e257 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #55: __libc_start_main + 0xe7 (0x7fd304392c87 in /lib/x86_64-linux-gnu/libc.so.6)
frame #56: <unknown function> + 0x1ce151 (0x556d4eb4e151 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
. This may indicate a possible application crash on rank 0 or a network set up issue.
torch.distributed.DistBackendError: [2] is setting up NCCL communicator and retrieving ncclUniqueId from [0] via c10d key-value store by key '0', but store->get('0') got error: Connection reset by peer
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:670 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f991e1e5d87 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5894fde (0x7f9959edefde in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0x360 (0x7f9959ed97f0 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x32 (0x7f9959ed9b32 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0xa1 (0x7f9959eda961 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7f9959e8fdd1 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7f9959e8fdd1 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7f9959e8fdd1 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7f9959e8fdd1 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #9: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7f9959e8fdd1 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #10: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, std::string const&, int) + 0xa9 (0x7f991f3614e9 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, int, bool) + 0x22b (0x7f991f3684db in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::recv(std::vector<at::Tensor, std::allocator<at::Tensor> >&, int, int) + 0x550 (0x7f991f38b3e0 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #13: <unknown function> + 0x5838289 (0x7f9959e82289 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #14: <unknown function> + 0x5843180 (0x7f9959e8d180 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x5843215 (0x7f9959e8d215 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x4e8937c (0x7f99594d337c in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x1a08a38 (0x7f9956052a38 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #18: <unknown function> + 0x58498d4 (0x7f9959e938d4 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0x584eb85 (0x7f9959e98b85 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #20: <unknown function> + 0xc99c3e (0x7f996c743c3e in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #21: <unknown function> + 0x413f64 (0x7f996bebdf64 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #22: <unknown function> + 0x1457e6 (0x560e8ac7f7e6 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #23: _PyObject_MakeTpCall + 0x26b (0x560e8ac789db in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #24: <unknown function> + 0x151ec6 (0x560e8ac8bec6 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #25: _PyEval_EvalFrameDefault + 0x4c1a (0x560e8ac73f2a in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #26: _PyFunction_Vectorcall + 0x6c (0x560e8ac7fc6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #27: _PyEval_EvalFrameDefault + 0x4c1a (0x560e8ac73f2a in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #28: _PyFunction_Vectorcall + 0x6c (0x560e8ac7fc6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #29: _PyEval_EvalFrameDefault + 0x4c1a (0x560e8ac73f2a in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #30: _PyFunction_Vectorcall + 0x6c (0x560e8ac7fc6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #31: _PyEval_EvalFrameDefault + 0x13cc (0x560e8ac706dc in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #32: _PyFunction_Vectorcall + 0x6c (0x560e8ac7fc6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #33: _PyEval_EvalFrameDefault + 0x13cc (0x560e8ac706dc in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #34: _PyFunction_Vectorcall + 0x6c (0x560e8ac7fc6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #35: _PyEval_EvalFrameDefault + 0x4c1a (0x560e8ac73f2a in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #36: _PyFunction_Vectorcall + 0x6c (0x560e8ac7fc6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #37: _PyEval_EvalFrameDefault + 0x320 (0x560e8ac6f630 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #38: _PyFunction_Vectorcall + 0x6c (0x560e8ac7fc6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #39: _PyEval_EvalFrameDefault + 0x13cc (0x560e8ac706dc in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #40: _PyFunction_Vectorcall + 0x6c (0x560e8ac7fc6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #41: _PyEval_EvalFrameDefault + 0x320 (0x560e8ac6f630 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #42: _PyFunction_Vectorcall + 0x6c (0x560e8ac7fc6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #43: _PyEval_EvalFrameDefault + 0x320 (0x560e8ac6f630 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #44: _PyFunction_Vectorcall + 0x6c (0x560e8ac7fc6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #45: _PyEval_EvalFrameDefault + 0x13cc (0x560e8ac706dc in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #46: <unknown function> + 0x1da820 (0x560e8ad14820 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #47: PyEval_EvalCode + 0x87 (0x560e8ad14767 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #48: <unknown function> + 0x20ac2a (0x560e8ad44c2a in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #49: <unknown function> + 0x206023 (0x560e8ad40023 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #50: <unknown function> + 0x9a558 (0x560e8abd4558 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #51: _PyRun_SimpleFileObject + 0x1ae (0x560e8ad3a50e in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #52: _PyRun_AnyFileObject + 0x44 (0x560e8ad3a0a4 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #53: Py_RunMain + 0x38b (0x560e8ad3729b in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #54: Py_BytesMain + 0x37 (0x560e8ad08257 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #55: __libc_start_main + 0xe7 (0x7f996e5dcc87 in /lib/x86_64-linux-gnu/libc.so.6)
frame #56: <unknown function> + 0x1ce151 (0x560e8ad08151 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
. This may indicate a possible application crash on rank 0 or a network set up issue.
    return pg.recv([tensor], group_src_rank, tag)
torch.distributed.DistBackendError: [2] is setting up NCCL communicator and retrieving ncclUniqueId from [0] via c10d key-value store by key '0', but store->get('0') got error: Connection reset by peer
Exception raised from recvBytes at ../torch/csrc/distributed/c10d/Utils.hpp:670 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f2914fd9d87 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5894fde (0x7f2950cd2fde in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::string>, std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0x360 (0x7f2950ccd7f0 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::string const&) + 0x32 (0x7f2950ccdb32 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::string const&) + 0xa1 (0x7f2950cce961 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7f2950c83dd1 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7f2950c83dd1 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7f2950c83dd1 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7f2950c83dd1 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #9: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7f2950c83dd1 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #10: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, std::string const&, int) + 0xa9 (0x7f29161554e9 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #11: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, int, bool) + 0x22b (0x7f291615c4db in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::recv(std::vector<at::Tensor, std::allocator<at::Tensor> >&, int, int) + 0x550 (0x7f291617f3e0 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #13: <unknown function> + 0x5838289 (0x7f2950c76289 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #14: <unknown function> + 0x5843180 (0x7f2950c81180 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x5843215 (0x7f2950c81215 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x4e8937c (0x7f29502c737c in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x1a08a38 (0x7f294ce46a38 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #18: <unknown function> + 0x58498d4 (0x7f2950c878d4 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0x584eb85 (0x7f2950c8cb85 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #20: <unknown function> + 0xc99c3e (0x7f2963537c3e in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #21: <unknown function> + 0x413f64 (0x7f2962cb1f64 in /gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #22: <unknown function> + 0x1457e6 (0x55ad7a6b97e6 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #23: _PyObject_MakeTpCall + 0x26b (0x55ad7a6b29db in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #24: <unknown function> + 0x151ec6 (0x55ad7a6c5ec6 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #25: _PyEval_EvalFrameDefault + 0x4c1a (0x55ad7a6adf2a in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #26: _PyFunction_Vectorcall + 0x6c (0x55ad7a6b9c6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #27: _PyEval_EvalFrameDefault + 0x4c1a (0x55ad7a6adf2a in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #28: _PyFunction_Vectorcall + 0x6c (0x55ad7a6b9c6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #29: _PyEval_EvalFrameDefault + 0x4c1a (0x55ad7a6adf2a in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #30: _PyFunction_Vectorcall + 0x6c (0x55ad7a6b9c6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #31: _PyEval_EvalFrameDefault + 0x13cc (0x55ad7a6aa6dc in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #32: _PyFunction_Vectorcall + 0x6c (0x55ad7a6b9c6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #33: _PyEval_EvalFrameDefault + 0x13cc (0x55ad7a6aa6dc in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #34: _PyFunction_Vectorcall + 0x6c (0x55ad7a6b9c6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #35: _PyEval_EvalFrameDefault + 0x4c1a (0x55ad7a6adf2a in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #36: _PyFunction_Vectorcall + 0x6c (0x55ad7a6b9c6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #37: _PyEval_EvalFrameDefault + 0x320 (0x55ad7a6a9630 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #38: _PyFunction_Vectorcall + 0x6c (0x55ad7a6b9c6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #39: _PyEval_EvalFrameDefault + 0x13cc (0x55ad7a6aa6dc in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #40: _PyFunction_Vectorcall + 0x6c (0x55ad7a6b9c6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #41: _PyEval_EvalFrameDefault + 0x320 (0x55ad7a6a9630 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #42: _PyFunction_Vectorcall + 0x6c (0x55ad7a6b9c6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #43: _PyEval_EvalFrameDefault + 0x320 (0x55ad7a6a9630 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #44: _PyFunction_Vectorcall + 0x6c (0x55ad7a6b9c6c in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #45: _PyEval_EvalFrameDefault + 0x13cc (0x55ad7a6aa6dc in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #46: <unknown function> + 0x1da820 (0x55ad7a74e820 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #47: PyEval_EvalCode + 0x87 (0x55ad7a74e767 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #48: <unknown function> + 0x20ac2a (0x55ad7a77ec2a in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #49: <unknown function> + 0x206023 (0x55ad7a77a023 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #50: <unknown function> + 0x9a558 (0x55ad7a60e558 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #51: _PyRun_SimpleFileObject + 0x1ae (0x55ad7a77450e in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #52: _PyRun_AnyFileObject + 0x44 (0x55ad7a7740a4 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #53: Py_RunMain + 0x38b (0x55ad7a77129b in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #54: Py_BytesMain + 0x37 (0x55ad7a742257 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
frame #55: __libc_start_main + 0xe7 (0x7f29653d0c87 in /lib/x86_64-linux-gnu/libc.so.6)
frame #56: <unknown function> + 0x1ce151 (0x55ad7a742151 in /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10)
. This may indicate a possible application crash on rank 0 or a network set up issue.
[2024-12-25 14:45:09,391] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 22734) of binary: /gf3/home/fjs/anaconda3/envs/megatron/bin/python3.10
Traceback (most recent call last):
  File "/gf3/home/fjs/anaconda3/envs/megatron/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/gf3/home/fjs/anaconda3/envs/megatron/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
examples/multimodal/train.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-12-25_14:45:09
  host      : gn52
  rank      : 9 (local_rank: 1)
  exitcode  : 1 (pid: 22735)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-12-25_14:45:09
  host      : gn52
  rank      : 10 (local_rank: 2)
  exitcode  : 1 (pid: 22736)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-12-25_14:45:09
  host      : gn52
  rank      : 11 (local_rank: 3)
  exitcode  : 1 (pid: 22737)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-12-25_14:45:09
  host      : gn52
  rank      : 8 (local_rank: 0)
  exitcode  : 1 (pid: 22734)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
